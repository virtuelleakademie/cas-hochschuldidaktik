---
title: "Wie funktionieren Chatbots?"
---

## Was sind Chatbots?

:::: {.columns}
::: {.column width="30%"}

:::

::: {.column width="70%"}
![](../../assets/images/claude.png)
:::
::::

## Was sind LLMs?

:::: {.columns}
::: {.column width="60%"}
Ein LLM kann man sich wie einen ausgefeilten Autocomplete-Mechanismus vorstellen.
:::
::: {.column width="40%"}
![](../../assets/images/predictive-text.png)
:::
::::

:::{.attribution}
Bildquelle: [www.apple.com](https://www.apple.com)
:::



## Was sind LLMs?
- Statistische Modelle, die Text analysieren, um das nächste Wort vorherzusagen.

::: {.hidden}
$$
\newcommand{\purple}[1]{\color{purple}{#1}}
\newcommand{\red}[1]{\color{red}{#1}}
\newcommand{\blue}[1]{\color{blue}{#1}}
$$
:::

$$\purple{P(\text{Wort}_{i+1}} \mid \blue{\text{Kontext}}, \red{\text{Modell}})$$



- Jede $\purple{\text{Vorhersage}}$ basiert auf dem $\blue{\text{Kontext}}$ und dem internen $\red{\text{Modell}}$.




## Vorhersage

Nicht alle Teile des Kontexts sind gleich wichtig:

<br> <br>

<!-- :::{.callout-note appearance="minimal"}-->
:::{.r-fit-text}
_"Die Familie, die sehr wohlhabend war, lebte in einem grossen Haus. Das Haus stand inmitten eines weitläufigen Gartens. Es war bekannt für seine prächtige Fassade und die grosszügigen ___"_
::: 

:::{.attribution}
Nach Thomas Mann, *Buddenbrooks*
:::

<br> <br>

Welche Wörter sind besonders wichtig, um 

- die Bedeutung des Satzes zu erfassen?
- das nächste Wort vorherzusagen?


## Kontext verstehen {.smaller}

:::{.callout-note appearance="minimal"}
"Die Familie, die sehr wohlhabend war, lebte in einem grossen Haus. Das Haus stand inmitten eines weitläufigen Gartens. Es war bekannt für seine prächtige Fassade und die grosszügigen ___"
:::

**Syntaktische Struktur (Grammatik und Struktur des Satzes):**

- Das Wort "grosszügigen" ist ein Adjektiv, das wahrscheinlich ein Nomen---im Plural---beschreibt (Dativ oder Akkusativ wegen der Endung "-en").
- Der Satz bezieht sich auf das Haus und den Garten, daher liegt der Fokus vermutlich auf deren Eigenschaften.

**Semantischer Kontext (Bedeutung):**

Die Beschreibung hebt Wohlstand hervor. Das nächste Wort beschreibt vermutlich etwas Luxuriöses oder Weitläufiges.

**Lexikalische Kohärenz (Wörter und deren Bedeutungen im Kontext):**

Nach "grosszügigen" folgen häufig Nomen, die Räume, Flächen oder architektonische Elemente beschreiben, z. B. "Räume", "Gärten", "Fenster".





## Wie generieren LLMs Text?

<br> <br>

![](../../assets/images/wort-fuer-wort.png)


<!-- ## Wie können LLMs Text vorhersagen? {.smaller}

Sie werden trainiert, das nächste Wort in einer gegebenen Wortsequenz zu erraten.

:::: {.columns}
::: {.column width="50%"}
Ein LLM wird in drei Schritten aufgebaut:

1. Sammeln eines grossen Text-Korpus.
2. Basierend auf diesem Text, muss das Modell das nächste Wort in einer gegebenen Wortsequenz vorherzusagen lernen.
3. Das Sprachmodell wird feiner abgestimmt, um das gewünschte Verhalten zu erreichen.

:::
::: {.column width="50%"}
![](../../assets/images/LLM-Bookshelf.png)
:::
:::: -->


## Wie werden LLMs trainiert?

![](../../assets/images/llm-training.png)


## Gefahren und Herausforderungen

:::: {.columns}
::: {.column width="50%"}
:::{.r-fit-text}
Die verschiedenen Stufen des Trainings sind mit verschiedenen Arten von Bedenken verbunden:

- **Urheberrecht**: Die trainierten Modelle werden mit Texten trainiert, die möglicherweise Urheberrechtlich geschützt sind.
- **Bias**: Die trainierten Modelle können bestehende Vorurteile aus den Trainingsdaten lernen.
- **Energieverbrauch**: Das Training der Modelle verbraucht viel Energie und ist damit umweltbelastend.
:::

:::
::: {.column width="50%"}
![](../../assets/images/Pothole.png)
:::
::::

## Gefahren und Herausforderungen

:::: {.columns}
::: {.column width="50%"}
:::{.r-fit-text}
- Obschon sich LLMs viel Wissen aneignen[^1], werden sie nicht trainiert, faktisch korrekte Aussagen zu machen.
- Dies bedeutet, dass wir alle Aussagen, die LLMs uns präsentieren, immer kritisch hinterfragen müssen.
- LLMs sind **keine Wissensdatenbanken**. Informationen immer anhand externer Quellen überprüfen.
:::
:::
::: {.column width="50%"}
![](../../assets/images/KnowledgeBase.png)
:::
::::

[^1]: Das ganze Wissen, welches nötig ist, um Texte Wort für Wort vorherzusagen.
